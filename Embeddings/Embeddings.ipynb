{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mixedbread-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixedbread_ai.client import MixedbreadAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "MIXEDBREAD_API_KEY = os.getenv('MIXEDBREAD_API_KEY')\n",
    "DATA_DIRECTORY = os.getenv('DATA_DIRECTORY')\n",
    "\n",
    "with open(f'{DATA_DIRECTORY}/chunks.json', 'r', encoding='utf-8') as file:\n",
    "    textbook_chunks = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxbai = MixedbreadAI(api_key=MIXEDBREAD_API_KEY)\n",
    "\n",
    "def get_embeddings(queries):\n",
    "    res = mxbai.embeddings(\n",
    "        model='mixedbread-ai/mxbai-embed-large-v1',\n",
    "        input=queries,\n",
    "        normalized=True,\n",
    "        encoding_format='float',\n",
    "        truncation_strategy='start'\n",
    "    )\n",
    "\n",
    "    embeddings = np.array([res.data[i].embedding for i in range(len(res.data))])\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_similarity(embedding1, embedding2):\n",
    "    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning, Chapter 5, 51 chunks\n",
      "Deep Learning, Chapter 6, 66 chunks\n",
      "Deep Learning, Chapter 8, 29 chunks\n",
      "Deep Learning, Chapter 9, 9 chunks\n",
      "Deep Learning, Chapter 14, 2 chunks\n",
      "Stanford CS229, Chapter 5, 13 chunks\n",
      "Stanford CS229, Chapter 6, 23 chunks\n",
      "Stanford CS229, Chapter 7, 26 chunks\n",
      "Stanford CS229, Chapter 8, 10 chunks\n",
      "Stanford CS229, Chapter 9, 11 chunks\n",
      "Stanford CS229, Chapter 11, 2 chunks\n",
      "Math for Machine Learning, Chapter 3, 13 chunks\n",
      "Math for Machine Learning, Chapter 4, 47 chunks\n",
      "Math for Machine Learning, Chapter 5, 7 chunks\n",
      "Math for Machine Learning, Chapter 6, 14 chunks\n",
      "Math for Machine Learning, Chapter 7, 15 chunks\n",
      "Math for Machine Learning, Chapter 12, 34 chunks\n",
      "The Elements of Statistical Learning, Chapter 7.10, 11 chunks\n",
      "The Elements of Statistical Learning, Chapter 8.2, 9 chunks\n",
      "The Elements of Statistical Learning, Chapter 8.3, 6 chunks\n",
      "The Elements of Statistical Learning, Chapter 12, 27 chunks\n",
      "An Introduction to Statistical Learning, Chapter 6.2, 19 chunks\n",
      "An Introduction to Statistical Learning, Chapter 2.2.2, 6 chunks\n",
      "An Introduction to Statistical Learning, Chapter 9, 27 chunks\n",
      "An Introduction to Statistical Learning, Chapter 10, 45 chunks\n"
     ]
    }
   ],
   "source": [
    "embedded_chunks = {}\n",
    "\n",
    "for book_name, book_info in textbook_chunks.items():\n",
    "    embedded_chunks[book_name] = {\n",
    "        \"authors\": book_info.get(\"authors\", []),\n",
    "        \"year\": book_info.get(\"year\", \"\"),\n",
    "        \"chapters\": []\n",
    "    }\n",
    "    for chapter in book_info['chapters']:\n",
    "        for chapter_number, chunks in chapter.items():\n",
    "            print(f\"{book_name}, Chapter {chapter_number}, {len(chunks)} chunks\")\n",
    "            embeddings = get_embeddings(chunks)\n",
    "            embedded_chunks[book_name][\"chapters\"].append({chapter_number: embeddings.tolist()})\n",
    "\n",
    "with open(f'{DATA_DIRECTORY}/embedded_chunks.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(embedded_chunks, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_DIRECTORY}/chunks.json', 'r', encoding='utf-8') as file:\n",
    "    textbook_chunks = json.load(file)\n",
    "with open(f'{DATA_DIRECTORY}/embedded_chunks.json', 'r', encoding='utf-8') as file:\n",
    "    embedded_chunks = json.load(file)\n",
    "\n",
    "data = []\n",
    "for book_name, book_info in textbook_chunks.items():\n",
    "    for chapter_index, chapter in enumerate(book_info['chapters']):\n",
    "        for chapter_number, chunks in chapter.items():\n",
    "            embeddings = embedded_chunks[book_name]['chapters'][chapter_index][chapter_number]\n",
    "            for chunk_index, chunk in enumerate(chunks):\n",
    "                data.append({\n",
    "                    'id': len(data) + 1,\n",
    "                    'embedding': embeddings[chunk_index],\n",
    "                    'content': chunk,\n",
    "                    'textbook': book_name,\n",
    "                    'chapter': chapter_number\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f'{DATA_DIRECTORY}/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
